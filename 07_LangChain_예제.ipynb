{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaP5d6T1N5APiX4yFJGzxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cserock/colab-examples/blob/main/07_LangChain_%EC%98%88%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경변수 파일(.env) 설정하기\n",
        "/content/drive/MyDrive/lg-dx/에 아래 내용으로 .env 파일을 작성한 후 업로드합니다.  \n",
        "\n",
        "OPENAI_API_KEY=sk-xxxx  \n",
        "LANGCHAIN_TRACING_V2=\"true\"  \n",
        "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"  \n",
        "LANGCHAIN_API_KEY=\"lsv2_xxxx  \n",
        "LANGCHAIN_PROJECT=\"lg-dx\"\n"
      ],
      "metadata": {
        "id": "eoksbWnx6A_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive 마운트"
      ],
      "metadata": {
        "id": "SrxSN4xR3iHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdCJSo3r3Gcu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "python-dotenv 라이브러리 설치"
      ],
      "metadata": {
        "id": "npStTZ2y6Rbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "id6QUnS15x85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "환경변수 파일 로드 및 확인"
      ],
      "metadata": {
        "id": "fvTi5Fiu6T3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/drive/MyDrive/lg-dx/.env', override=True)\n",
        "\n",
        "import os\n",
        "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
        "print(\"openai_api_key : \" + openai_api_key)\n",
        "langchain_api_key = os.environ.get('LANGCHAIN_API_KEY')\n",
        "print(\"langchain_api_key : \" + langchain_api_key)"
      ],
      "metadata": {
        "id": "9Amh_A0751Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain 설치 및 업데이트"
      ],
      "metadata": {
        "id": "RqTUSGKB6hy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain 설치 및 업데이트\n",
        "!pip install -qU langchain-teddynote"
      ],
      "metadata": {
        "id": "dG-p0nGL6dxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설치된 LangChain 버전을 확인합니다."
      ],
      "metadata": {
        "id": "_cRC0zLG6tRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"[LangChain 관련 패키지 버전]\")\n",
        "for package_name in [\n",
        "    \"langchain\",\n",
        "    \"langchain-core\",\n",
        "    \"langchain-experimental\",\n",
        "    \"langchain-community\",\n",
        "    \"langchain-openai\",\n",
        "    \"langchain-teddynote\",\n",
        "    \"langchain-huggingface\",\n",
        "    \"langchain-google-genai\",\n",
        "    \"langchain-anthropic\",\n",
        "    \"langchain-cohere\",\n",
        "    \"langchain-chroma\",\n",
        "    \"langchain-elasticsearch\",\n",
        "    \"langchain-upstage\",\n",
        "    \"langchain-cohere\",\n",
        "    \"langchain-milvus\",\n",
        "    \"langchain-text-splitters\",\n",
        "]:\n",
        "    try:\n",
        "        package_version = version(package_name)\n",
        "        print(f\"{package_name}: {package_version}\")\n",
        "    except ImportError:\n",
        "        print(f\"{package_name}: 설치되지 않음\")"
      ],
      "metadata": {
        "id": "l9omSYOX6uKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmith 추적 설정  \n",
        ".env 파일에 LangSmith API 키가 설정 되어 있어야 합니다.(LANGCHAIN_API_KEY)"
      ],
      "metadata": {
        "id": "g2QNeARu93Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"lg-dx-langchain\")"
      ],
      "metadata": {
        "id": "5dejbxN_-kNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래와 같이 추적을 끌 수 있습니다."
      ],
      "metadata": {
        "id": "ioPKHHtC-sgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
        "logging.langsmith(\"lg-dx-langchain\", set_enable=False)"
      ],
      "metadata": {
        "id": "OxbDCEdD-xVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API"
      ],
      "metadata": {
        "id": "-bGxvT-z-6r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 객체 생성\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
        "    model_name=\"gpt-4o-mini\",  # 모델명\n",
        ")\n",
        "\n",
        "# 질의내용\n",
        "question = \"대한민국의 수도는 어디인가요?\"\n",
        "\n",
        "# 질의\n",
        "response = llm.invoke(question)\n",
        "print(f\"[답변]: {response}\")"
      ],
      "metadata": {
        "id": "uPcOloJ1--_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# content 출력\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "xmx_7L0Z_oxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metadata 출력\n",
        "print(response.response_metadata)"
      ],
      "metadata": {
        "id": "KLlYPng8_zaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogProb 활성화\n",
        "주어진 텍스트에 대한 모델의 토큰 확률의 로그 값 을 의미합니다. 토큰이란 문장을 구성하는 개별 단어나 문자 등의 요소를 의미하고, 확률은 모델이 그 토큰을 예측할 확률을 나타냅니다."
      ],
      "metadata": {
        "id": "Cd9Wysjq_8ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 객체 생성\n",
        "llm_with_logprob = ChatOpenAI(\n",
        "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
        "    max_tokens=2048,  # 최대 토큰수\n",
        "    model_name=\"gpt-4o-mini\",  # 모델명\n",
        ").bind(logprobs=True)\n",
        "\n",
        "# 질의내용\n",
        "question = \"대한민국의 수도는 어디인가요?\"\n",
        "\n",
        "# 질의\n",
        "response = llm_with_logprob.invoke(question)\n",
        "\n",
        "# 결과 출력\n",
        "response.response_metadata\n"
      ],
      "metadata": {
        "id": "KR6PZD_gADPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 스트리밍 출력\n",
        "스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다."
      ],
      "metadata": {
        "id": "8RLCyJcdAM0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스트림 방식으로 질의\n",
        "# answer 에 스트리밍 답변의 결과를 받습니다.\n",
        "answer = llm.stream(\"대한민국의 아름다운 관광지 10곳과 주소를 알려주세요!\")\n",
        "\n",
        "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
        "for token in answer:\n",
        "    print(token.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "id": "p0zZQukNAPm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 멀티모달 모델(이미지 인식)\n",
        "멀티모달은 여러 가지 형태의 정보(모달)를 통합하여 처리하는 기술이나 접근 방식을 의미합니다. 이는 다음과 같은 다양한 데이터 유형을 포함할 수 있습니다.  \n",
        "\n",
        "- 텍스트: 문서, 책, 웹 페이지 등의 글자로 된 정보  \n",
        "- 이미지: 사진, 그래픽, 그림 등 시각적 정보  \n",
        "- 오디오: 음성, 음악, 소리 효과 등의 청각적 정보  \n",
        "- 비디오: 동영상 클립, 실시간 스트리밍 등 시각적 및 청각적 정보의 결합"
      ],
      "metadata": {
        "id": "EfpSb9NhBhFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote.models import MultiModal\n",
        "from langchain_teddynote.messages import stream_response\n",
        "\n",
        "# 객체 생성\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
        "    max_tokens=2048,  # 최대 토큰수\n",
        "    model_name=\"gpt-4o\",  # 모델명\n",
        ")\n",
        "\n",
        "# 멀티모달 객체 생성\n",
        "multimodal_llm = MultiModal(llm)\n",
        "\n",
        "# 샘플 이미지 주소(웹사이트로 부터 바로 인식)\n",
        "IMAGE_URL = \"https://t3.ftcdn.net/jpg/03/77/33/96/360_F_377339633_Rtv9I77sSmSNcev8bEcnVxTHrXB4nRJ5.jpg\"\n",
        "\n",
        "# 이미지 파일로 부터 질의\n",
        "answer = multimodal_llm.stream(IMAGE_URL)\n",
        "\n",
        "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
        "stream_response(answer)"
      ],
      "metadata": {
        "id": "Zl1ya0ilBmbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System, User 프롬프트 수정"
      ],
      "metadata": {
        "id": "npiO7ughCFRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"당신은 표(재무제표) 를 해석하는 금융 AI 어시스턴트 입니다.\n",
        "당신의 임무는 주어진 테이블 형식의 재무제표를 바탕으로 흥미로운 사실을 정리하여 친절하게 답변하는 것입니다.\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"당신에게 주어진 표는 회사의 재무제표 입니다. 흥미로운 사실을 정리하여 답변하세요.\"\"\"\n",
        "\n",
        "# 멀티모달 객체 생성\n",
        "multimodal_llm_with_prompt = MultiModal(\n",
        "    llm, system_prompt=system_prompt, user_prompt=user_prompt\n",
        ")\n",
        "\n",
        "# 이미지의 경로 입력\n",
        "IMAGE_PATH_FROM_FILE = \"https://storage.googleapis.com/static.fastcampus.co.kr/prod/uploads/202212/080345-661/kwon-01.png\"\n",
        "\n",
        "# 이미지 파일로 부터 질의(스트림 방식)\n",
        "answer = multimodal_llm_with_prompt.stream(IMAGE_PATH_FROM_FILE)\n",
        "\n",
        "# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\n",
        "stream_response(answer)"
      ],
      "metadata": {
        "id": "NsBYXZkuCJAU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}