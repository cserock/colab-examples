{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOHhElJTKWMoerFMEyAwQ5K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cserock/colab-examples/blob/main/07_RAG_web_QA_%EC%98%88%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경변수 파일(.env) 설정하기\n",
        "/content/drive/MyDrive/lg-dx/에 아래 내용으로 .env 파일을 작성한 후 업로드합니다.  \n",
        "\n",
        "OPENAI_API_KEY=sk-xxxx  \n",
        "LANGCHAIN_TRACING_V2=\"true\"  \n",
        "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"  \n",
        "LANGCHAIN_API_KEY=\"lsv2_xxxx  \n",
        "LANGCHAIN_PROJECT=\"lg-dx\"\n"
      ],
      "metadata": {
        "id": "eoksbWnx6A_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive 마운트"
      ],
      "metadata": {
        "id": "SrxSN4xR3iHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdCJSo3r3Gcu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "python-dotenv 라이브러리 설치"
      ],
      "metadata": {
        "id": "npStTZ2y6Rbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "id6QUnS15x85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "환경변수 파일 로드 및 확인"
      ],
      "metadata": {
        "id": "fvTi5Fiu6T3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/drive/MyDrive/lg-dx/.env', override=True)\n",
        "\n",
        "import os\n",
        "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
        "print(\"openai_api_key : \" + openai_api_key)\n",
        "langchain_api_key = os.environ.get('LANGCHAIN_API_KEY')\n",
        "print(\"langchain_api_key : \" + langchain_api_key)"
      ],
      "metadata": {
        "id": "9Amh_A0751Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain 설치 및 업데이트"
      ],
      "metadata": {
        "id": "RqTUSGKB6hy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain 설치 및 업데이트\n",
        "!pip install -qU langchain-teddynote langchain_community pymupdf faiss-cpu"
      ],
      "metadata": {
        "id": "dG-p0nGL6dxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설치된 LangChain 버전을 확인합니다."
      ],
      "metadata": {
        "id": "_cRC0zLG6tRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"[LangChain 관련 패키지 버전]\")\n",
        "for package_name in [\n",
        "    \"langchain\",\n",
        "    \"langchain-core\",\n",
        "    \"langchain-experimental\",\n",
        "    \"langchain-community\",\n",
        "    \"langchain-openai\",\n",
        "    \"langchain-teddynote\",\n",
        "    \"langchain-huggingface\",\n",
        "    \"langchain-google-genai\",\n",
        "    \"langchain-anthropic\",\n",
        "    \"langchain-cohere\",\n",
        "    \"langchain-chroma\",\n",
        "    \"langchain-elasticsearch\",\n",
        "    \"langchain-upstage\",\n",
        "    \"langchain-cohere\",\n",
        "    \"langchain-milvus\",\n",
        "    \"langchain-text-splitters\",\n",
        "]:\n",
        "    try:\n",
        "        package_version = version(package_name)\n",
        "        print(f\"{package_name}: {package_version}\")\n",
        "    except ImportError:\n",
        "        print(f\"{package_name}: 설치되지 않음\")"
      ],
      "metadata": {
        "id": "l9omSYOX6uKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmith 추적 설정  \n",
        ".env 파일에 LangSmith API 키가 설정 되어 있어야 합니다.(LANGCHAIN_API_KEY)"
      ],
      "metadata": {
        "id": "xRayr3zeJqiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"lg-dx-rag-web\")"
      ],
      "metadata": {
        "id": "e1cR18pjJraR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네이버 뉴스 기반 QA(Question-Answering) 챗봇\n",
        "이번 튜토리얼에는 네이버 뉴스기사의 내용에 대해 질문할 수 있는 뉴스기사 QA 앱 을 구축할 것입니다.  \n",
        "\n",
        "이 가이드에서는 OpenAI 챗 모델과 임베딩, 그리고 Chroma 벡터 스토어를 사용할 것입니다.  \n",
        "\n",
        "먼저 다음의 과정을 통해 간단한 인덱싱 파이프라인과 RAG 체인을 약 20줄의 코드로 구현할 수 있습니다.\n",
        "- bs4는 웹 페이지를 파싱하기 위한 라이브러리입니다.\n",
        "- langchain은 AI와 관련된 다양한 기능을 제공하는 라이브러리로, 여기서는 특히 텍스트 분할(RecursiveCharacterTextSplitter), 문서 로딩(WebBaseLoader), 벡터 저장(Chroma, FAISS), 출력 파싱(StrOutputParser), 실행 가능한 패스스루(RunnablePassthrough) 등을 다룹니다.  \n",
        "- langchain_openai 모듈을 통해 OpenAI의 챗봇(ChatOpenAI)과 임베딩(OpenAIEmbeddings) 기능을 사용할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "7bqfKe1X8vLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "OxbDCEdD-xVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG 기본 파이프라인(1~8단계)"
      ],
      "metadata": {
        "id": "-bGxvT-z-6r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "-CQPARxPJ2zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 1: 문서 로드(Load Documents)\n",
        "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://n.news.naver.com/article/437/0000378416\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            \"div\",\n",
        "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "docs"
      ],
      "metadata": {
        "id": "pn9c6BSYLJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 2: 문서 분할(Split Documents)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "len(splits)"
      ],
      "metadata": {
        "id": "jVA9DnCELY7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 3: 임베딩(Embedding) 생성\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# 단계 4: DB 생성(Create DB) 및 저장\n",
        "# 벡터스토어를 생성합니다.\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)"
      ],
      "metadata": {
        "id": "PvYDjUWtLcdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 5: 검색기(Retriever) 생성\n",
        "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
        "# 검색 결과 4개(default)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 검색 결과 8개\n",
        "# retriever = vectorstore.as_retriever(search_kwargs={\"k\": 8})\n"
      ],
      "metadata": {
        "id": "0OrYGedwM_Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 6: 프롬프트 생성(Create Prompt)\n",
        "# 프롬프트를 생성합니다.\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
        "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "X3dZO7NiNEX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 7: 언어모델(LLM) 생성\n",
        "# 모델(LLM) 을 생성합니다.\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "tBCSRhMfNIYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 8: 체인(Chain) 생성\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "M8bIunnYNL-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 체인 실행(Run Chain)\n",
        "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
        "answer = chain.invoke(\"부영그룹의 출산 장려 정책에 대해 설명해주세요.\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "zdcD0-2fNOY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain.invoke(\"부영그룹은 출산 직원에게 얼마의 지원을 제공하나요?\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "dDZtf3xCTMiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain.invoke(\"정부의 저출생 대책을 bullet points 형식으로 작성해 주세요.\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "9B83vvoDTVOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain.invoke(\"부영그룹의 임직원 숫자는 몇명인가요?\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "l5oNYEppTbTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}