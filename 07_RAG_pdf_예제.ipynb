{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7bqfKe1X8vLp"
      ],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPgBgAo/bNQaT6/LemsHhu2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cserock/colab-examples/blob/main/07_RAG_pdf_%EC%98%88%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경변수 파일(.env) 설정하기\n",
        "/content/drive/MyDrive/lg-dx/에 아래 내용으로 .env 파일을 작성한 후 업로드합니다.  \n",
        "\n",
        "OPENAI_API_KEY=sk-xxxx  \n",
        "LANGCHAIN_TRACING_V2=\"true\"  \n",
        "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"  \n",
        "LANGCHAIN_API_KEY=\"lsv2_xxxx  \n",
        "LANGCHAIN_PROJECT=\"lg-dx\"\n"
      ],
      "metadata": {
        "id": "eoksbWnx6A_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive 마운트"
      ],
      "metadata": {
        "id": "SrxSN4xR3iHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdCJSo3r3Gcu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "python-dotenv 라이브러리 설치"
      ],
      "metadata": {
        "id": "npStTZ2y6Rbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "id6QUnS15x85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "환경변수 파일 로드 및 확인"
      ],
      "metadata": {
        "id": "fvTi5Fiu6T3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/drive/MyDrive/lg-dx/.env', override=True)\n",
        "\n",
        "import os\n",
        "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
        "print(\"openai_api_key : \" + openai_api_key)\n",
        "langchain_api_key = os.environ.get('LANGCHAIN_API_KEY')\n",
        "print(\"langchain_api_key : \" + langchain_api_key)"
      ],
      "metadata": {
        "id": "9Amh_A0751Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain 설치 및 업데이트"
      ],
      "metadata": {
        "id": "RqTUSGKB6hy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain 설치 및 업데이트\n",
        "!pip install -qU langchain-teddynote langchain_community pymupdf faiss-cpu"
      ],
      "metadata": {
        "id": "dG-p0nGL6dxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "설치된 LangChain 버전을 확인합니다."
      ],
      "metadata": {
        "id": "_cRC0zLG6tRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"[LangChain 관련 패키지 버전]\")\n",
        "for package_name in [\n",
        "    \"langchain\",\n",
        "    \"langchain-core\",\n",
        "    \"langchain-experimental\",\n",
        "    \"langchain-community\",\n",
        "    \"langchain-openai\",\n",
        "    \"langchain-teddynote\",\n",
        "    \"langchain-huggingface\",\n",
        "    \"langchain-google-genai\",\n",
        "    \"langchain-anthropic\",\n",
        "    \"langchain-cohere\",\n",
        "    \"langchain-chroma\",\n",
        "    \"langchain-elasticsearch\",\n",
        "    \"langchain-upstage\",\n",
        "    \"langchain-cohere\",\n",
        "    \"langchain-milvus\",\n",
        "    \"langchain-text-splitters\",\n",
        "]:\n",
        "    try:\n",
        "        package_version = version(package_name)\n",
        "        print(f\"{package_name}: {package_version}\")\n",
        "    except ImportError:\n",
        "        print(f\"{package_name}: 설치되지 않음\")"
      ],
      "metadata": {
        "id": "l9omSYOX6uKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmith 추적 설정  \n",
        ".env 파일에 LangSmith API 키가 설정 되어 있어야 합니다.(LANGCHAIN_API_KEY)"
      ],
      "metadata": {
        "id": "xRayr3zeJqiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"lg-dx-rag-pdf\")"
      ],
      "metadata": {
        "id": "e1cR18pjJraR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF 파일 다운로드\n",
        "실습을 위해 다운로드 받은 파일을 data 폴더로 복사해 주세요.\n",
        "\n",
        "소프트웨어정책연구소(SPRi) - 2023년 12월호  \n",
        "\n",
        "저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)  \n",
        "링크: https://spri.kr/posts/view/23669  \n",
        "파일명: SPRI_AI_Brief_2023년12월호_F.pdf  \n"
      ],
      "metadata": {
        "id": "7bqfKe1X8vLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangSmith 추적 설정  \n",
        ".env 파일에 LangSmith API 키가 설정 되어 있어야 합니다.(LANGCHAIN_API_KEY)"
      ],
      "metadata": {
        "id": "g2QNeARu93Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"lg-dx-rag\")"
      ],
      "metadata": {
        "id": "5dejbxN_-kNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래와 같이 추적을 끌 수 있습니다."
      ],
      "metadata": {
        "id": "ioPKHHtC-sgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
        "logging.langsmith(\"lg-dx-rag\", set_enable=False)"
      ],
      "metadata": {
        "id": "OxbDCEdD-xVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG 기본 파이프라인(1~8단계)"
      ],
      "metadata": {
        "id": "-bGxvT-z-6r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "-CQPARxPJ2zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 1: 문서 로드(Load Documents)\n",
        "loader = PyMuPDFLoader(\"/content/drive/MyDrive/lg-dx/data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 페이지수: {len(docs)}\")"
      ],
      "metadata": {
        "id": "pn9c6BSYLJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 2: 문서 분할(Split Documents)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "print(f\"분할된 청크의수: {len(split_documents)}\")"
      ],
      "metadata": {
        "id": "jVA9DnCELY7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 3: 임베딩(Embedding) 생성\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# 단계 4: DB 생성(Create DB) 및 저장\n",
        "# 벡터스토어를 생성합니다.\n",
        "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
      ],
      "metadata": {
        "id": "PvYDjUWtLcdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 5: 검색기(Retriever) 생성\n",
        "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
        "# 검색 결과 4개(default)\n",
        "# retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 검색 결과 8개\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 8})\n"
      ],
      "metadata": {
        "id": "0OrYGedwM_Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색기에 쿼리를 날려 검색된 chunk 결과를 확인합니다.\n",
        "retriever.invoke(\"삼성전자가 자체 개발한 AI 의 이름은?\")"
      ],
      "metadata": {
        "id": "NatQ90a5M7XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 6: 프롬프트 생성(Create Prompt)\n",
        "# 프롬프트를 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Answer in Korean.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "X3dZO7NiNEX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 7: 언어모델(LLM) 생성\n",
        "# 모델(LLM) 을 생성합니다.\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "tBCSRhMfNIYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단계 8: 체인(Chain) 생성\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "M8bIunnYNL-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 체인 실행(Run Chain)\n",
        "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
        "question = \"삼성전자가 자체 개발한 AI 의 이름은?\"\n",
        "response = chain.invoke(question)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "zdcD0-2fNOY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}